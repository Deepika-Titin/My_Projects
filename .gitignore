my.html
PremaPaalagam/
Data-analysis/ecommerce_sentiment_analysis/data/Reviews.csv

Data-analysis/Day-2 Milk_analysis.xlsx
Data-analysis/My_Energy_Tracker.xlsx
Excel-analysis/
LuckyRa/

Professional-projects/Data-analysis/ecommerce_sentiment_analysis/data/Reviews.csvProfessional-projects/Data-analysis/ecommerce_sentiment_analysis/data/Reviews.csv
Professional-projects/Data-analysis/ecommerce_sentiment_analysis/data/Reviews.csv

Data-analysis/customer_churn_sql/data/customer_churn_dataset-testing-master.csv
Data-analysis/customer_churn_sql/image/
Data-analysis/ecommerce_sentiment_analysis/data/Reviews.csv
Data-analysis/sales_insights/data/
Data-analysis/sales_insights/images/
Data-analysis/sales_insights/reports/

echo "Professional-projects/Data-analysis/ecommerce_sentiment_analysis/data/Reviews.csv" >> .gitignore
git add .gitignore
git commit -m "Ignore large CSV file to fix GitHub push limit"

Professional-projects/Data-analysis/ecommerce_sentiment_analysis/data/Reviews.csv


# Ignore virtual environments
venv/
**/venv/

# Ignore large datasets
*.csv
*.xlsx

# Ignore Power BI files
*.pbix

# Ignore Python cache
__pycache__/
*.pyc
Data-analysis/ecommerce_sentiment_analysis/data/


# Ignore heavy and personal files
*.csv
*.xlsx
*.pdf
*.pbix
*.png
*.jpg
*.jpeg

# Ignore local virtual environments
venv/
Data-analysis/**/venv/

# Ignore entire personal project folders
LuckyRa/
Excel-analysis/

# Ignore large dataset file that caused errors
Professional-projects/Data-analysis/ecommerce_sentiment_analysis/data/Reviews.csv
